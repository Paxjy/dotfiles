name: Local Assistant
version: 1.0.0
schema: v1
models:

  - name: qwen3-8B-vllm
    provider: vllm
    apiBase: http://localhost:8000/v1
    model: Qwen/Qwen3-8B-AWQ
    # defaultCompletionOptions:
    #   contextLength: 16384
    #   maxTokens: 8192
    capabilities:
      - tool_use
    chatOptions: 
      baseSystemMessage: ""
    roles:
      - chat
      - edit
      - apply

  - name: r1-qwen3-8B-mac
    provider: openai
    apiBase: http://192.168.1.57:8080/v1
    model: r1-qwen3-8b
    defaultCompletionOptions:
      contextLength: 16384
      maxTokens: 8192
    capabilities:
      - tool_use
    chatOptions: 
      baseSystemMessage: ""
    roles:
      - chat
      - edit
      - apply

  - name: r1-qwen3-8B
    provider: openai
    apiBase: http://localhost:8080/v1
    model: r1-qwen3-8b
    defaultCompletionOptions:
      contextLength: 16384
      maxTokens: 8192
    capabilities:
      - tool_use
    chatOptions: 
      baseSystemMessage: ""
    roles:
      - chat
      - edit
      - apply


  - name: llama3.1-8b
    provider: openai
    apiBase: http://localhost:8080/v1
    model: llama3.1-8b
    defaultCompletionOptions:
      contextLength: 16384
      maxTokens: 8192
    capabilities:
      - tool_use
    # chatOptions: 
    #   baseSystemMessage: ""
    roles:
      - chat
      - edit
      - apply

  - name: Gemma3-12b
    provider: openai
    apiBase: http://localhost:8080/v1
    model: gemma3-12b
    defaultCompletionOptions:
      contextLength: 16384
      maxTokens: 8192
    capabilities:
      - image_input
    # chatOptions: 
    #   baseSystemMessage: ""
    roles:
      - chat
      - edit
      - apply

  - name: Qwen3-30B
    provider: openai
    apiBase: http://localhost:8080/v1
    model: qwen3-30B
    defaultCompletionOptions:
      contextLength: 16384
      maxTokens: 8192
    capabilities:
      - tool_use
    # chatOptions: 
    #   baseSystemMessage: ""
    roles:
      - chat
      - edit
      - apply
      
  - name: Qwen2.5-coder-7b
    provider: openai
    apiBase: http://localhost:8080/v1
    model: qwen2.5-coder-7b
    defaultCompletionOptions:
      contextLength: 16384
      maxTokens: 8192
    roles:
      - autocomplete
  
  - name: Magistral
    provider: openai
    apiBase: http://localhost:8080/v1
    model: magistral
    defaultCompletionOptions:
      contextLength: 16384
      maxTokens: 8192
    capabilities:
      - image_input
    # chatOptions: 
    #   baseSystemMessage: ""
    roles:
      - chat
      - edit
      - apply

context:
  - provider: code
  - provider: docs
  - provider: diff
  - provider: terminal
  - provider: problems
  - provider: folder
  - provider: codebase
